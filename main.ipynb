{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Object Detection using OpenCV without Machine Learning (ML)\n",
    "# Approach\n",
    "# 1. Read image\n",
    "# 2. Convert image to grayscale\n",
    "# 3. Increase contrast of image using log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Image list\n",
    "# 1. No Tumor\n",
    "img_no_tumor = [\"img/no (1).jpg\", \"img/no (2).jpg\", \"img/no (3).jpg\", \"img/no (4).jpg\", \"img/no (5).jpg\", \"img/no (6).jpg\", \"img/no (7).jpg\", \"img/no (8).jpg\", \"img/no (9).jpg\", \"img/no (10).jpg\"]\n",
    "# 2. Tumor\n",
    "img_yes_tumor = [\"img/gg (1).jpg\", \"img/gg (2).jpg\", \"img/gg (3).jpg\", \"img/gg (4).jpg\", \"img/m (1).jpg\", \"img/m (2).jpg\", \"img/m (3).jpg\", \"img/m (4).jpg\", \"img/m (5).jpg\", \"img/m (6).jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 1. Read image\n",
    "df_no_tumor = []\n",
    "df_yes_tumor = []\n",
    "\n",
    "for img in img_no_tumor:\n",
    "    df_no_tumor.append(cv2.imread(img))\n",
    "\n",
    "for img in img_yes_tumor:\n",
    "    df_yes_tumor.append(cv2.imread(img))\n",
    "\n",
    "# Show images\n",
    "# for i in range(5, 10):\n",
    "#     cv2.imshow(\"No Tumor\", df_no_tumor[i])\n",
    "#     cv2.imshow(\"Yes Tumor\", df_yes_tumor[i])\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 2. Convert image to grayscale\n",
    "gray_no_tumor = []\n",
    "gray_yes_tumor = []\n",
    "\n",
    "for img in df_no_tumor:\n",
    "    gray_no_tumor.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "for img in df_yes_tumor:\n",
    "    gray_yes_tumor.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "# Show images\n",
    "# for i in range(5, 10):\n",
    "#     cv2.imshow(\"No Tumor\", gray_no_tumor[i])\n",
    "#     cv2.imshow(\"Yes Tumor\", gray_yes_tumor[i])\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 3. Cropped to ROI\n",
    "cropped_no_tumor = []\n",
    "cropped_yes_tumor = []\n",
    "\n",
    "# Ref: https://github.com/MohamedAliHabib/Brain-Tumor-Detection/blob/master/Brain%20Tumor%20Detection.ipynb\n",
    "for img in gray_no_tumor:\n",
    "    # Thresholding\n",
    "    threshold = cv2.threshold(img.copy(), 40, 255, cv2.THRESH_OTSU)[1]\n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Get the largest contour\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    # Find extreme points\n",
    "    extleft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extright = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    exttop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extbot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    # Crop the image\n",
    "    cropped = img[exttop[1] : extbot[1], extleft[0] : extright[0]]\n",
    "    cropped_no_tumor.append(cropped)\n",
    "\n",
    "for img in gray_yes_tumor:\n",
    "    # Thresholding\n",
    "    threshold = cv2.threshold(img.copy(), 40, 255, cv2.THRESH_OTSU)[1]\n",
    "    # Find contour\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Get the largest contour\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    # Find extreme points\n",
    "    extleft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extright = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    exttop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extbot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    # Crop the image\n",
    "    cropped = img[exttop[1] : extbot[1], extleft[0] : extright[0]]\n",
    "    cropped_yes_tumor.append(cropped)\n",
    "\n",
    "# Show cropped images compare to original images\n",
    "# for i in range(5, 10):\n",
    "#     cv2.imshow(\"Original No Tumor\", gray_no_tumor[i])\n",
    "#     cv2.imshow(\"No Tumor\", cropped_no_tumor[i])\n",
    "#     cv2.imshow(\"Original Yes Tumor\", gray_yes_tumor[i])\n",
    "#     cv2.imshow(\"Yes Tumor\", cropped_yes_tumor[i])\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 4. Thresholding\n",
    "thres_no_tumor = []\n",
    "thres_yes_tumor = []\n",
    "\n",
    "adapThres_no_tumor = []\n",
    "adapThres_yes_tumor = []\n",
    "\n",
    "\n",
    "thresh = 100\n",
    "\n",
    "block_size = 55\n",
    "c = -15\n",
    "\n",
    "\n",
    "for img in cropped_no_tumor:\n",
    "    _, thres = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)\n",
    "    thres_no_tumor.append(thres)\n",
    "    adapThres = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    adapThres_no_tumor.append(adapThres)\n",
    "\n",
    "\n",
    "for img in cropped_yes_tumor:\n",
    "    _, thres = cv2.threshold(img, thresh, 255, cv2.THRESH_BINARY)\n",
    "    thres_yes_tumor.append(thres)\n",
    "    adapThres = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    adapThres_yes_tumor.append(adapThres)\n",
    "\n",
    "\n",
    "# stack images side by side\n",
    "# for i in range(0, 9):\n",
    "#     stacked_no_tumor = np.hstack((cropped_no_tumor[i], thres_no_tumor[i], adapThres_no_tumor[i]))\n",
    "#     stacked_yes_tumor = np.hstack((cropped_yes_tumor[i], thres_yes_tumor[i], adapThres_yes_tumor[i]))\n",
    "#     cv2.imshow(\"No Tumor\", stacked_no_tumor)\n",
    "#     cv2.imshow(\"Yes Tumor\", stacked_yes_tumor)\n",
    "#     cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 5. Identify ROI\n",
    "cont_no_tumor = []\n",
    "contdraw_no_tumor = []\n",
    "cont_yes_tumor = []\n",
    "contdraw_yes_tumor = []\n",
    "\n",
    "bound_no_tumor = []\n",
    "bound_yes_tumor = []\n",
    "\n",
    "min_scale = 0.005\n",
    "max_scale = 0.35\n",
    "\n",
    "# Find contour, bounding box, bounding box area, draw bounding box\n",
    "for img in thres_no_tumor:\n",
    "    # Contour\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    cv2.drawContours(new_canvas, contours, -1, (255, 255, 255), 1)\n",
    "    cont_no_tumor.append(new_canvas)\n",
    "\n",
    "    # Bounding box\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # Filter By Area\n",
    "        min_area = min_scale * img.shape[0] * img.shape[1]\n",
    "        max_area = max_scale * img.shape[0] * img.shape[1]\n",
    "        area = w * h\n",
    "        if min_area < area < max_area:\n",
    "            cv2.rectangle(new_canvas, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "    bound_no_tumor.append(new_canvas)\n",
    "\n",
    "for img in thres_yes_tumor:\n",
    "    # Contour\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    cv2.drawContours(new_canvas, contours, -1, (255, 255, 255), 1)\n",
    "    cont_yes_tumor.append(new_canvas)\n",
    "\n",
    "    # Bounding box\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # Check are must be between 20 to 80 percent of whole picture\n",
    "        min_area = min_scale * img.shape[0] * img.shape[1]\n",
    "        max_area = max_scale * img.shape[0] * img.shape[1]\n",
    "        area = w * h\n",
    "        if min_area < area < max_area:\n",
    "            cv2.rectangle(new_canvas, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "    bound_yes_tumor.append(new_canvas)\n",
    "\n",
    "# Show images\n",
    "for i in range(0, 9):\n",
    "    stacked_no_tumor = np.hstack((cropped_no_tumor[i], thres_no_tumor[i]))\n",
    "    stacked_yes_tumor = np.hstack((cropped_yes_tumor[i], thres_yes_tumor[i]))\n",
    "    stacked_no_tumor_cont_bound = np.hstack((cont_no_tumor[i], bound_no_tumor[i]))\n",
    "    stacked_yes_tumor_cont_bound = np.hstack((cont_yes_tumor[i], bound_yes_tumor[i]))\n",
    "    cv2.imshow(\"No Tumor\", stacked_no_tumor)\n",
    "    cv2.imshow(\"No Tumor Contour Bound\", stacked_no_tumor_cont_bound)\n",
    "    cv2.imshow(\"Yes Tumor\", stacked_yes_tumor)\n",
    "    cv2.imshow(\"Yes Tumor Contour Bound\", stacked_yes_tumor_cont_bound)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
