{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 1: Import Libraries and Load Images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Set the path to the images\n",
    "img = [\n",
    "    \"img/no (1).jpg\",\n",
    "    \"img/no (2).jpg\",\n",
    "    \"img/no (3).jpg\",\n",
    "    \"img/no (4).jpg\",\n",
    "    \"img/no (5).jpg\",\n",
    "    \"img/no (6).jpg\",\n",
    "    \"img/no (7).jpg\",\n",
    "    \"img/no (8).jpg\",\n",
    "    \"img/no (9).jpg\",\n",
    "    \"img/no (10).jpg\",\n",
    "    \"img/gg (1).jpg\",\n",
    "    \"img/gg (2).jpg\",\n",
    "    \"img/gg (3).jpg\",\n",
    "    \"img/gg (4).jpg\",\n",
    "    \"img/m (1).jpg\",\n",
    "    \"img/m (2).jpg\",\n",
    "    \"img/m (3).jpg\",\n",
    "    \"img/m (4).jpg\",\n",
    "    \"img/m (5).jpg\",\n",
    "    \"img/m (6).jpg\",\n",
    "]\n",
    "\n",
    "# Shuffle the images\n",
    "np.random.shuffle(img)\n",
    "\n",
    "# Prepare the correct answers\n",
    "correct_ans = []\n",
    "for i in img:\n",
    "    if \"no\" in i:\n",
    "        correct_ans.append(\"No\")\n",
    "    else:\n",
    "        correct_ans.append(\"Yes\")\n",
    "\n",
    "# Load the images in grayscale\n",
    "df_img = []\n",
    "for i in img:\n",
    "    df_img.append(cv2.imread(i, cv2.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 2: Preprocess the Images\n",
    "# Crop image of unwanted padding\n",
    "cropped_img = []\n",
    "for img in df_img:\n",
    "    # Threshold the image\n",
    "    threshold = cv2.threshold(img.copy(), 40, 255, cv2.THRESH_OTSU)[1]\n",
    "    # Find the contours\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Get largest contour\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    # Get extreme points of the contour\n",
    "    extleft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extright = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    exttop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extbot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    # Crop the image\n",
    "    cropped_img.append(img[exttop[1] : extbot[1], extleft[0] : extright[0]])\n",
    "\n",
    "# Show the cropped images\n",
    "# for i in range(len(cropped_img)):\n",
    "#     cv2.imshow(\"Cropped Image\", cropped_img[i])\n",
    "#     cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 3: Extract Features\n",
    "# 1. Thresholding\n",
    "threshold_img = []\n",
    "\n",
    "thres_val = 100\n",
    "\n",
    "for img in cropped_img:\n",
    "    _, thres = cv2.threshold(img.copy(), thres_val, 255, cv2.THRESH_BINARY)\n",
    "    threshold_img.append(thres)\n",
    "\n",
    "# 2. Erode and Dilate\n",
    "ed_img = []\n",
    "k_size = 3\n",
    "kernel = np.ones((k_size, k_size), np.uint8)\n",
    "total_iterations = 1\n",
    "e_iterations = 1\n",
    "d_iterations = 1\n",
    "for img in threshold_img:\n",
    "    for i in range(total_iterations):\n",
    "        erode = cv2.erode(img.copy(), kernel, iterations=e_iterations)\n",
    "        dilate = cv2.dilate(erode, kernel, iterations=d_iterations)\n",
    "    ed_img.append(dilate)\n",
    "\n",
    "# 3. Finding Contours, Draw Contours, Extract features\n",
    "contour_img = []\n",
    "features = []\n",
    "\n",
    "# Parameters\n",
    "\n",
    "for img in ed_img:\n",
    "    # Find the contours\n",
    "    contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    cv2.drawContours(new_canvas, contours, -1, (255, 255, 255), 1)\n",
    "    contour_img.append(contours)\n",
    "\n",
    "    # Draw bounding box\n",
    "    new_canvas = np.zeros_like(img)\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        min_area = min_scale * img.shape[0] * img.shape[1]\n",
    "        max_area = max_scale * img.shape[0] * img.shape[1]\n",
    "        area = w * h\n",
    "        bound_center = (x + w / 2, y + h / 2)\n",
    "        low_x = box_pos_factor * img.shape[1]\n",
    "        low_y = box_pos_factor * img.shape[0]\n",
    "        up_x = img.shape[1] - box_pos_factor * img.shape[1]\n",
    "        up_y = img.shape[0] - box_pos_factor * img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================== Step 4: Classify the Tumor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
